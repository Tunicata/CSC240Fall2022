{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 595,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "outputs": [
    {
     "data": {
      "text/plain": "   0                 1       2          3   4                   5   \\\n0  39         State-gov   77516  Bachelors  13       Never-married   \n1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n2  38           Private  215646    HS-grad   9            Divorced   \n3  53           Private  234721       11th   7  Married-civ-spouse   \n4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n\n                  6              7      8       9     10  11  12  \\\n0       Adm-clerical  Not-in-family  White    Male  2174   0  40   \n1    Exec-managerial        Husband  White    Male     0   0  13   \n2  Handlers-cleaners  Not-in-family  White    Male     0   0  40   \n3  Handlers-cleaners        Husband  Black    Male     0   0  40   \n4     Prof-specialty           Wife  Black  Female     0   0  40   \n\n              13     14  \n0  United-States  <=50K  \n1  United-States  <=50K  \n2  United-States  <=50K  \n3  United-States  <=50K  \n4           Cuba  <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in original data as a dataframe\n",
    "df = pd.read_csv('adult.data', header=None, skipinitialspace=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       32561 non-null  int64 \n",
      " 1   1       32561 non-null  object\n",
      " 2   2       32561 non-null  int64 \n",
      " 3   3       32561 non-null  object\n",
      " 4   4       32561 non-null  int64 \n",
      " 5   5       32561 non-null  object\n",
      " 6   6       32561 non-null  object\n",
      " 7   7       32561 non-null  object\n",
      " 8   8       32561 non-null  object\n",
      " 9   9       32561 non-null  object\n",
      " 10  10      32561 non-null  int64 \n",
      " 11  11      32561 non-null  int64 \n",
      " 12  12      32561 non-null  int64 \n",
      " 13  13      32561 non-null  object\n",
      " 14  14      32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\",\n",
    "            \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "outputs": [
    {
     "data": {
      "text/plain": "[8.0, -1, 147242.0, -1, 2.0, -1, -1, -1, -1, -1, 10000.0, 436.0, 10.0, -1]"
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sample = df.max()\n",
    "min_sample = df.min()\n",
    "steps = []\n",
    "\n",
    "for i in range(14):\n",
    "    try:\n",
    "        step = int(max_sample[i]) - int(min_sample[i])\n",
    "        steps.append(np.ceil(step/10))\n",
    "    except:\n",
    "        steps.append(-1)\n",
    "\n",
    "steps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Adm-clerical',\n 'Bachelors',\n 'Male',\n 'Never-married',\n 'Not-in-family',\n 'State-gov',\n 'United-States',\n 'White',\n 'age4',\n 'capital-gain0',\n 'capital-loss0',\n 'fnlwgt0',\n 'hours-per-week4'}"
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess data set\n",
    "adult_data = []\n",
    "\n",
    "for adult in df.values:\n",
    "    adult_set = set()\n",
    "    for i in range(14):\n",
    "        # ignore missing index\n",
    "        if adult[i] == \"?\":\n",
    "            pass\n",
    "        # convert continuous data to categorical ones based on the steps.\n",
    "        elif i in {0, 2, 10, 11, 12}:\n",
    "            adult_set.add(df_names[i] + str(int(np.floor(adult[i]/steps[i]))))\n",
    "        # ignore repeated data\n",
    "        elif i == 4:\n",
    "            pass\n",
    "        else:\n",
    "            adult_set.add(adult[i])\n",
    "    adult_data.append(adult_set)\n",
    "\n",
    "# cut the first 100 transactions as the test data set\n",
    "adult_data = adult_data[:100]\n",
    "adult_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "outputs": [
    {
     "data": {
      "text/plain": "([({'capital-gain0'}, 98),\n  ({'United-States'}, 83),\n  ({'capital-loss0'}, 95),\n  ({'Male'}, 74),\n  ({'hours-per-week4'}, 62),\n  ({'White'}, 81),\n  ({'Married-civ-spouse'}, 55),\n  ({'Private'}, 70),\n  ({'fnlwgt1'}, 54)],\n [{'United-States', 'capital-gain0'},\n  {'capital-gain0', 'capital-loss0'},\n  {'Male', 'capital-gain0'},\n  {'capital-gain0', 'hours-per-week4'},\n  {'White', 'capital-gain0'},\n  {'Married-civ-spouse', 'capital-gain0'},\n  {'Private', 'capital-gain0'},\n  {'capital-gain0', 'fnlwgt1'},\n  {'United-States', 'capital-loss0'},\n  {'Male', 'United-States'},\n  {'United-States', 'hours-per-week4'},\n  {'United-States', 'White'},\n  {'Married-civ-spouse', 'United-States'},\n  {'Private', 'United-States'},\n  {'United-States', 'fnlwgt1'},\n  {'Male', 'capital-loss0'},\n  {'capital-loss0', 'hours-per-week4'},\n  {'White', 'capital-loss0'},\n  {'Married-civ-spouse', 'capital-loss0'},\n  {'Private', 'capital-loss0'},\n  {'capital-loss0', 'fnlwgt1'},\n  {'Male', 'hours-per-week4'},\n  {'Male', 'White'},\n  {'Male', 'Married-civ-spouse'},\n  {'Male', 'Private'},\n  {'Male', 'fnlwgt1'},\n  {'White', 'hours-per-week4'},\n  {'Married-civ-spouse', 'hours-per-week4'},\n  {'Private', 'hours-per-week4'},\n  {'fnlwgt1', 'hours-per-week4'},\n  {'Married-civ-spouse', 'White'},\n  {'Private', 'White'},\n  {'White', 'fnlwgt1'},\n  {'Married-civ-spouse', 'Private'},\n  {'Married-civ-spouse', 'fnlwgt1'},\n  {'Private', 'fnlwgt1'}])"
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first scan\n",
    "def first_scan(data_set, min_support):\n",
    "    c1 = []\n",
    "    supports = []\n",
    "\n",
    "    # generate Candidate C1 and count support\n",
    "    for transaction in data_set:\n",
    "        for item in transaction:\n",
    "            if not {item} in c1:\n",
    "                c1.append({item})\n",
    "                supports.append(1)\n",
    "            else:\n",
    "                supports[c1.index({item})] += 1\n",
    "\n",
    "    # compare candidates with min_support\n",
    "    item_set = []\n",
    "    frequent_dict = []\n",
    "    for idx in range(len(c1)):\n",
    "        if supports[idx] >= min_support:\n",
    "            item_set.append(c1[idx])\n",
    "            frequent_dict.append((c1[idx], supports[idx]))\n",
    "\n",
    "    # generate new candidates\n",
    "    temp = list(itertools.combinations(item_set, 2))\n",
    "    temp = [set.union(combination[0], combination[1]) for combination in temp]\n",
    "    new_item_set = []\n",
    "    [new_item_set.append(candidate) for candidate in temp if not i in new_item_set]\n",
    "\n",
    "    return frequent_dict, new_item_set\n",
    "\n",
    "adult_c1 = first_scan(adult_data, 50)\n",
    "adult_c1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'a', 'b'}, {'b', 'c'}, {'a', 'c'}]"
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a helper function use to get the subsets with a specific length from a iterable object\n",
    "def power_set(iterable):\n",
    "    s = list(iterable)\n",
    "    return itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(len(s) + 1))\n",
    "\n",
    "def k_subsets(s, k):\n",
    "    return [set(item) for item in power_set(s) if len(item) == k]\n",
    "\n",
    "k_subsets({\"a\", \"b\", \"c\"}, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "outputs": [
    {
     "data": {
      "text/plain": "([({'United-States', 'capital-gain0'}, 81),\n  ({'capital-gain0', 'capital-loss0'}, 93),\n  ({'Male', 'capital-gain0'}, 74),\n  ({'capital-gain0', 'hours-per-week4'}, 61),\n  ({'White', 'capital-gain0'}, 79),\n  ({'Married-civ-spouse', 'capital-gain0'}, 55),\n  ({'Private', 'capital-gain0'}, 68),\n  ({'capital-gain0', 'fnlwgt1'}, 54),\n  ({'United-States', 'capital-loss0'}, 80),\n  ({'Male', 'United-States'}, 63),\n  ({'United-States', 'hours-per-week4'}, 51),\n  ({'United-States', 'White'}, 71),\n  ({'Private', 'United-States'}, 56),\n  ({'Male', 'capital-loss0'}, 71),\n  ({'capital-loss0', 'hours-per-week4'}, 60),\n  ({'White', 'capital-loss0'}, 77),\n  ({'Married-civ-spouse', 'capital-loss0'}, 51),\n  ({'Private', 'capital-loss0'}, 66),\n  ({'capital-loss0', 'fnlwgt1'}, 53),\n  ({'Male', 'White'}, 62),\n  ({'White', 'hours-per-week4'}, 51),\n  ({'Private', 'White'}, 57)],\n [{'United-States', 'capital-gain0', 'capital-loss0'},\n  {'Male', 'United-States', 'capital-gain0'},\n  {'United-States', 'capital-gain0', 'hours-per-week4'},\n  {'United-States', 'White', 'capital-gain0'},\n  {'Private', 'United-States', 'capital-gain0'},\n  {'Male', 'capital-gain0', 'capital-loss0'},\n  {'capital-gain0', 'capital-loss0', 'hours-per-week4'},\n  {'White', 'capital-gain0', 'capital-loss0'},\n  {'Married-civ-spouse', 'capital-gain0', 'capital-loss0'},\n  {'Private', 'capital-gain0', 'capital-loss0'},\n  {'capital-gain0', 'capital-loss0', 'fnlwgt1'},\n  {'Male', 'White', 'capital-gain0'},\n  {'White', 'capital-gain0', 'hours-per-week4'},\n  {'Private', 'White', 'capital-gain0'},\n  {'Male', 'United-States', 'capital-loss0'},\n  {'United-States', 'capital-loss0', 'hours-per-week4'},\n  {'United-States', 'White', 'capital-loss0'},\n  {'Private', 'United-States', 'capital-loss0'},\n  {'Male', 'United-States', 'White'},\n  {'United-States', 'White', 'hours-per-week4'},\n  {'Private', 'United-States', 'White'},\n  {'Male', 'White', 'capital-loss0'},\n  {'White', 'capital-loss0', 'hours-per-week4'},\n  {'Private', 'White', 'capital-loss0'}])"
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general scan function\n",
    "def scan(data_set, ck, min_support, print_flag=False):\n",
    "    supports = [0 for candidate in ck]\n",
    "    fre_data_sets = []\n",
    "\n",
    "    # count support of these candidates\n",
    "    for transaction in data_set:\n",
    "        fre_flag = False\n",
    "        for candidate in ck:\n",
    "            if candidate.issubset(transaction):\n",
    "                supports[ck.index(candidate)] += 1\n",
    "                fre_flag = True\n",
    "\n",
    "        # save the frequent transactions for the next scan, and discard the infrequent ones\n",
    "        if fre_flag:\n",
    "            fre_data_sets.append(transaction)\n",
    "\n",
    "    # compare candidates with min_support\n",
    "    frequent_item_sets = []\n",
    "    frequent_dict= []\n",
    "    for idx in range(len(ck)):\n",
    "        if supports[idx] >= min_support:\n",
    "            frequent_item_sets.append(ck[idx])\n",
    "            frequent_dict.append((ck[idx], supports[idx]))\n",
    "            if print_flag:\n",
    "                print(ck[idx], supports[idx])\n",
    "\n",
    "    if not frequent_item_sets:\n",
    "        return []\n",
    "\n",
    "    # generate new candidates\n",
    "    k_num = len(frequent_item_sets[0])\n",
    "\n",
    "    temp = list(itertools.combinations(frequent_item_sets, 2))\n",
    "    temp = [combination[0].union(combination[1]) for combination in temp\n",
    "            if combination[0]&combination[1] and len(combination[0]&combination[1]) == k_num-1]\n",
    "\n",
    "    new_item_set = []\n",
    "\n",
    "    # check whether those candidates repeated or have infrequent subsets\n",
    "    for candidate in temp:\n",
    "        if candidate not in new_item_set:\n",
    "            subsets = k_subsets(candidate, k_num)\n",
    "            flag = True\n",
    "            for item in subsets:\n",
    "                if item not in frequent_item_sets:\n",
    "                    flag = False\n",
    "                    break\n",
    "            if flag:\n",
    "                new_item_set.append(candidate)\n",
    "\n",
    "    return frequent_dict, new_item_set, fre_data_sets\n",
    "\n",
    "adult_c2 = scan(adult_data, adult_c1[1], 50)\n",
    "\n",
    "adult_c2[:2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "outputs": [
    {
     "data": {
      "text/plain": "[({'capital-gain0'}, 98),\n ({'United-States'}, 83),\n ({'capital-loss0'}, 95),\n ({'Male'}, 74),\n ({'hours-per-week4'}, 62),\n ({'White'}, 81),\n ({'Married-civ-spouse'}, 55),\n ({'Private'}, 70),\n ({'fnlwgt1'}, 54),\n ({'United-States', 'capital-gain0'}, 81),\n ({'capital-gain0', 'capital-loss0'}, 93),\n ({'Male', 'capital-gain0'}, 74),\n ({'capital-gain0', 'hours-per-week4'}, 61),\n ({'White', 'capital-gain0'}, 79),\n ({'Married-civ-spouse', 'capital-gain0'}, 55),\n ({'Private', 'capital-gain0'}, 68),\n ({'capital-gain0', 'fnlwgt1'}, 54),\n ({'United-States', 'capital-loss0'}, 80),\n ({'Male', 'United-States'}, 63),\n ({'United-States', 'hours-per-week4'}, 51),\n ({'United-States', 'White'}, 71),\n ({'Private', 'United-States'}, 56),\n ({'Male', 'capital-loss0'}, 71),\n ({'capital-loss0', 'hours-per-week4'}, 60),\n ({'White', 'capital-loss0'}, 77),\n ({'Married-civ-spouse', 'capital-loss0'}, 51),\n ({'Private', 'capital-loss0'}, 66),\n ({'capital-loss0', 'fnlwgt1'}, 53),\n ({'Male', 'White'}, 62),\n ({'White', 'hours-per-week4'}, 51),\n ({'Private', 'White'}, 57),\n ({'United-States', 'capital-gain0', 'capital-loss0'}, 78),\n ({'Male', 'United-States', 'capital-gain0'}, 63),\n ({'United-States', 'capital-gain0', 'hours-per-week4'}, 50),\n ({'United-States', 'White', 'capital-gain0'}, 69),\n ({'Private', 'United-States', 'capital-gain0'}, 54),\n ({'Male', 'capital-gain0', 'capital-loss0'}, 71),\n ({'capital-gain0', 'capital-loss0', 'hours-per-week4'}, 59),\n ({'White', 'capital-gain0', 'capital-loss0'}, 75),\n ({'Married-civ-spouse', 'capital-gain0', 'capital-loss0'}, 51),\n ({'Private', 'capital-gain0', 'capital-loss0'}, 64),\n ({'capital-gain0', 'capital-loss0', 'fnlwgt1'}, 53),\n ({'Male', 'White', 'capital-gain0'}, 62),\n ({'White', 'capital-gain0', 'hours-per-week4'}, 50),\n ({'Private', 'White', 'capital-gain0'}, 55),\n ({'Male', 'United-States', 'capital-loss0'}, 60),\n ({'United-States', 'White', 'capital-loss0'}, 68),\n ({'Private', 'United-States', 'capital-loss0'}, 54),\n ({'Male', 'United-States', 'White'}, 55),\n ({'Male', 'White', 'capital-loss0'}, 59),\n ({'Private', 'White', 'capital-loss0'}, 54),\n ({'Male', 'United-States', 'capital-gain0', 'capital-loss0'}, 60),\n ({'United-States', 'White', 'capital-gain0', 'capital-loss0'}, 66),\n ({'Private', 'United-States', 'capital-gain0', 'capital-loss0'}, 52),\n ({'Male', 'United-States', 'White', 'capital-gain0'}, 55),\n ({'Male', 'White', 'capital-gain0', 'capital-loss0'}, 59),\n ({'Private', 'White', 'capital-gain0', 'capital-loss0'}, 52),\n ({'Male', 'United-States', 'White', 'capital-loss0'}, 52),\n ({'Male', 'United-States', 'White', 'capital-gain0', 'capital-loss0'}, 52)]"
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integrate previous functions\n",
    "\n",
    "def apriori(data_set, min_sup):\n",
    "    frequent_item_set = []\n",
    "\n",
    "    temp_frequent_dict, ck = first_scan(data_set, min_sup)\n",
    "    frequent_item_set += temp_frequent_dict\n",
    "\n",
    "    while ck:\n",
    "        temp_frequent_dict, ck, data_set = scan(data_set, ck, min_sup)\n",
    "        frequent_item_set += temp_frequent_dict\n",
    "\n",
    "    return frequent_item_set\n",
    "\n",
    "adult_fre_item_set = apriori(adult_data, 50)\n",
    "adult_fre_item_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male => {Male, United-States}, Confidence = 0.8513513513513513\n"
     ]
    }
   ],
   "source": [
    "# the confidence for two frequent item sets\n",
    "def confidence(frequent_item0, frequent_item1, frequent_item_set):\n",
    "    union = frequent_item0.union(frequent_item1)\n",
    "    union_support = 0\n",
    "    item0_support = 0\n",
    "\n",
    "    for item in frequent_item_set:\n",
    "        if item[0] == union:\n",
    "            union_support = item[1]\n",
    "        if item[0] == frequent_item0:\n",
    "            item0_support = item[1]\n",
    "        if union_support and item0_support:\n",
    "            break\n",
    "    if item0_support:\n",
    "        return union_support/item0_support\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print('Male => {Male, United-States}, Confidence =',\n",
    "      confidence({'Male'}, {'Male', 'United-States'} ,adult_fre_item_set))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "outputs": [],
   "source": [
    "# fp tree node\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, item, fre_count):\n",
    "        self.item = item\n",
    "        self.fre_count = fre_count\n",
    "        self.children = set()\n",
    "        self.node_link = None\n",
    "\n",
    "    def increment(self, fre=1):\n",
    "        self.fre_count += fre\n",
    "\n",
    "    def add_child(self, new_node):\n",
    "        self.children.add(new_node)\n",
    "        return new_node\n",
    "\n",
    "    def get_child(self, item):\n",
    "        for child in self.children:\n",
    "            if child.item == item:\n",
    "                return child\n",
    "        return None\n",
    "\n",
    "    def display(self, level=0):\n",
    "        print(\"|\"*level+\"-\" ,self.item, self.fre_count)\n",
    "        for child in self.children:\n",
    "            child.display(level+1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "outputs": [
    {
     "data": {
      "text/plain": "(('England',\n  [{'Assoc-acdm',\n    'Divorced',\n    'England',\n    'Exec-managerial',\n    'Female',\n    'Private',\n    'Unmarried',\n    'White',\n    'age6',\n    'capital-gain0',\n    'capital-loss0',\n    'fnlwgt1',\n    'hours-per-week4'}]),\n ['fnlwgt1', 54, None])"
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transfer the data set to vertical version with a head table\n",
    "def vertical_transfer(data_set, min_sup):\n",
    "    vertical_data = {}\n",
    "    item_seq = []\n",
    "\n",
    "    # generate the vertical data set\n",
    "    for transaction in data_set:\n",
    "        for item in transaction:\n",
    "            if not item in vertical_data.keys():\n",
    "                vertical_data[item] = [transaction]\n",
    "                item_seq.append(item)\n",
    "            else:\n",
    "                vertical_data[item].append(transaction)\n",
    "\n",
    "    item_seq = [[item, len(vertical_data[item]), None] for item in item_seq if len(vertical_data[item]) >= min_sup]\n",
    "    item_seq.sort(key=(lambda x: x[1]), reverse=True)\n",
    "\n",
    "    return vertical_data, item_seq\n",
    "\n",
    "adult_vertical_data, adult_head_table = vertical_transfer(adult_data, 50)\n",
    "adult_vertical_data.popitem(), adult_head_table.pop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bacon', 3, <__main__.Node object at 0x0000021C3DACDD88>]\n",
      "['eggs', 2, <__main__.Node object at 0x0000021C3DACD988>]\n",
      "['soup', 2, <__main__.Node object at 0x0000021C3DACDF88>]\n",
      "['apple', 1, <__main__.Node object at 0x0000021C3DACDFC8>]\n",
      "['banana', 1, <__main__.Node object at 0x0000021C3DACDA08>]\n",
      "- None -1\n",
      "|- bacon 3\n",
      "||- eggs 2\n",
      "|||- soup 1\n",
      "|||- apple 1\n",
      "||- soup 1\n",
      "|||- banana 1\n",
      "['capital-gain0', 98, <__main__.Node object at 0x0000021C73DAD248>]\n",
      "['capital-loss0', 95, <__main__.Node object at 0x0000021C73DAD148>]\n",
      "['United-States', 83, <__main__.Node object at 0x0000021C73DAD1C8>]\n",
      "['White', 81, <__main__.Node object at 0x0000021C73DAD088>]\n",
      "['Male', 74, <__main__.Node object at 0x0000021C73DAD188>]\n",
      "['Private', 70, <__main__.Node object at 0x0000021C73DAD048>]\n",
      "['hours-per-week4', 62, <__main__.Node object at 0x0000021C73DAD108>]\n",
      "['Married-civ-spouse', 55, <__main__.Node object at 0x0000021C73DAD0C8>]\n",
      "['fnlwgt1', 54, <__main__.Node object at 0x0000021C788A8608>]\n",
      "- None -1\n",
      "|- capital-loss0 2\n",
      "||- United-States 2\n",
      "|||- White 2\n",
      "||||- Private 2\n",
      "|||||- hours-per-week4 1\n",
      "|- capital-gain0 98\n",
      "||- United-States 3\n",
      "|||- White 3\n",
      "||||- Male 3\n",
      "|||||- Married-civ-spouse 1\n",
      "||||||- fnlwgt1 1\n",
      "|||||- Private 2\n",
      "||||||- hours-per-week4 2\n",
      "|||||||- Married-civ-spouse 1\n",
      "||- capital-loss0 93\n",
      "|||- Male 4\n",
      "||||- hours-per-week4 1\n",
      "|||||- Married-civ-spouse 1\n",
      "||||- Private 2\n",
      "|||||- hours-per-week4 2\n",
      "||||||- Married-civ-spouse 2\n",
      "|||||||- fnlwgt1 1\n",
      "||||- Married-civ-spouse 1\n",
      "|||||- fnlwgt1 1\n",
      "|||- Private 2\n",
      "||||- hours-per-week4 1\n",
      "|||||- Married-civ-spouse 1\n",
      "||||- fnlwgt1 1\n",
      "|||- United-States 78\n",
      "||||- White 66\n",
      "|||||- Male 52\n",
      "||||||- hours-per-week4 11\n",
      "|||||||- Married-civ-spouse 9\n",
      "||||||||- fnlwgt1 5\n",
      "|||||||- fnlwgt1 1\n",
      "||||||- fnlwgt1 3\n",
      "||||||- Married-civ-spouse 4\n",
      "|||||||- fnlwgt1 3\n",
      "||||||- Private 32\n",
      "|||||||- hours-per-week4 21\n",
      "||||||||- fnlwgt1 6\n",
      "||||||||- Married-civ-spouse 14\n",
      "|||||||||- fnlwgt1 10\n",
      "|||||||- fnlwgt1 1\n",
      "|||||||- Married-civ-spouse 6\n",
      "||||||||- fnlwgt1 3\n",
      "|||||- Private 12\n",
      "||||||- hours-per-week4 8\n",
      "|||||||- Married-civ-spouse 3\n",
      "||||||||- fnlwgt1 2\n",
      "|||||||- fnlwgt1 2\n",
      "|||||- hours-per-week4 1\n",
      "||||||- fnlwgt1 1\n",
      "||||- Private 4\n",
      "|||||- fnlwgt1 1\n",
      "|||||- hours-per-week4 2\n",
      "||||||- Married-civ-spouse 1\n",
      "||||- Male 8\n",
      "|||||- Married-civ-spouse 1\n",
      "|||||- Private 4\n",
      "||||||- hours-per-week4 2\n",
      "|||||||- Married-civ-spouse 1\n",
      "||||||||- fnlwgt1 1\n",
      "|||||||- fnlwgt1 1\n",
      "||||||- Married-civ-spouse 1\n",
      "|||||||- fnlwgt1 1\n",
      "||||||- fnlwgt1 1\n",
      "|||||- hours-per-week4 3\n",
      "||||||- fnlwgt1 1\n",
      "||||||- Married-civ-spouse 2\n",
      "|||- White 9\n",
      "||||- Male 7\n",
      "|||||- Private 6\n",
      "||||||- hours-per-week4 5\n",
      "|||||||- fnlwgt1 2\n",
      "|||||||- Married-civ-spouse 3\n",
      "||||||||- fnlwgt1 2\n",
      "||||||- Married-civ-spouse 1\n",
      "|||||- hours-per-week4 1\n",
      "||||||- fnlwgt1 1\n",
      "||||- Private 2\n",
      "|||||- hours-per-week4 1\n",
      "||||||- fnlwgt1 1\n",
      "|||||- fnlwgt1 1\n",
      "||- Private 1\n",
      "|||- Married-civ-spouse 1\n",
      "||- White 1\n",
      "|||- Private 1\n",
      "||||- Married-civ-spouse 1\n"
     ]
    }
   ],
   "source": [
    "# function construct the fp tree\n",
    "def tree_construction(data_set, min_sup, display=False):\n",
    "    vertical_data, head_table = vertical_transfer(data_set, min_sup)\n",
    "\n",
    "    fp_tree = Node(None, -1)\n",
    "\n",
    "    # scan the data_set again\n",
    "    for transaction in data_set:\n",
    "        current_node = fp_tree\n",
    "        for item in head_table:\n",
    "            if item[0] in transaction:\n",
    "                child_node = current_node.get_child(item[0])\n",
    "                if child_node:\n",
    "                    child_node.increment()\n",
    "                else:\n",
    "                    child_node = current_node.add_child(Node(item[0], 1))\n",
    "                    if item[2]:\n",
    "                        next_link = item[2]\n",
    "                        while next_link.node_link:\n",
    "                            next_link = next_link.node_link\n",
    "                        next_link.node_link = child_node\n",
    "                    else:\n",
    "                        item[2] = child_node\n",
    "\n",
    "                current_node = child_node\n",
    "\n",
    "    if display:\n",
    "        for line in head_table:\n",
    "            print(line)\n",
    "        fp_tree.display()\n",
    "\n",
    "    return head_table, fp_tree\n",
    "\n",
    "itemSetList = [['eggs', 'bacon', 'soup'],\n",
    "                ['eggs', 'bacon', 'apple'],\n",
    "                ['soup', 'bacon', 'banana']]\n",
    "\n",
    "tree_construction(itemSetList, 0, True)\n",
    "h, t = tree_construction(adult_data, 50, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-74842517",
   "language": "python",
   "display_name": "PyCharm (CSC240)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}