{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1729,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from random import shuffle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1730,
   "outputs": [
    {
     "data": {
      "text/plain": "   0                 1       2          3   4                   5   \\\n0  39         State-gov   77516  Bachelors  13       Never-married   \n1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n2  38           Private  215646    HS-grad   9            Divorced   \n3  53           Private  234721       11th   7  Married-civ-spouse   \n4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n\n                  6              7      8       9     10  11  12  \\\n0       Adm-clerical  Not-in-family  White    Male  2174   0  40   \n1    Exec-managerial        Husband  White    Male     0   0  13   \n2  Handlers-cleaners  Not-in-family  White    Male     0   0  40   \n3  Handlers-cleaners        Husband  Black    Male     0   0  40   \n4     Prof-specialty           Wife  Black  Female     0   0  40   \n\n              13     14  \n0  United-States  <=50K  \n1  United-States  <=50K  \n2  United-States  <=50K  \n3  United-States  <=50K  \n4           Cuba  <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in original data as a dataframe\n",
    "df = pd.read_csv('adult.data', header=None, skipinitialspace=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1731,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       32561 non-null  int64 \n",
      " 1   1       32561 non-null  object\n",
      " 2   2       32561 non-null  int64 \n",
      " 3   3       32561 non-null  object\n",
      " 4   4       32561 non-null  int64 \n",
      " 5   5       32561 non-null  object\n",
      " 6   6       32561 non-null  object\n",
      " 7   7       32561 non-null  object\n",
      " 8   8       32561 non-null  object\n",
      " 9   9       32561 non-null  object\n",
      " 10  10      32561 non-null  int64 \n",
      " 11  11      32561 non-null  int64 \n",
      " 12  12      32561 non-null  int64 \n",
      " 13  13      32561 non-null  object\n",
      " 14  14      32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\",\n",
    "            \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1732,
   "outputs": [
    {
     "data": {
      "text/plain": "[8.0, -1, 147242.0, -1, 2.0, -1, -1, -1, -1, -1, 10000.0, 436.0, 10.0, -1]"
     },
     "execution_count": 1732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sample = df.max()\n",
    "min_sample = df.min()\n",
    "steps = []\n",
    "\n",
    "for i in range(14):\n",
    "    try:\n",
    "        step = int(max_sample[i]) - int(min_sample[i])\n",
    "        steps.append(np.ceil(step/10))\n",
    "    except:\n",
    "        steps.append(-1)\n",
    "\n",
    "steps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1733,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Adm-clerical',\n 'Bachelors',\n 'Male',\n 'Never-married',\n 'Not-in-family',\n 'State-gov',\n 'United-States',\n 'White',\n 'age4',\n 'capital-gain0',\n 'capital-loss0',\n 'fnlwgt0',\n 'hours-per-week4'}"
     },
     "execution_count": 1733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess data set\n",
    "adult_data = []\n",
    "\n",
    "for adult in df.values:\n",
    "    adult_set = set()\n",
    "    for i in range(14):\n",
    "        # ignore missing index\n",
    "        if adult[i] == \"?\":\n",
    "            pass\n",
    "        # convert continuous data to categorical ones based on the steps.\n",
    "        elif i in {0, 2, 10, 11, 12}:\n",
    "            adult_set.add(df_names[i] + str(int(np.floor(adult[i]/steps[i]))))\n",
    "        # ignore repeated data\n",
    "        elif i == 4:\n",
    "            pass\n",
    "        else:\n",
    "            adult_set.add(adult[i])\n",
    "    adult_data.append(adult_set)\n",
    "\n",
    "# cut the first 100 transactions as the test data set\n",
    "adult_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1734,
   "outputs": [],
   "source": [
    "# first scan\n",
    "def first_scan(data_set, min_support):\n",
    "    c1 = []\n",
    "    supports = []\n",
    "\n",
    "    # generate Candidate C1 and count support\n",
    "    for transaction in data_set:\n",
    "        for item in transaction:\n",
    "            if not {item} in c1:\n",
    "                c1.append({item})\n",
    "                supports.append(1)\n",
    "            else:\n",
    "                supports[c1.index({item})] += 1\n",
    "\n",
    "    # compare candidates with min_support\n",
    "    item_set = []\n",
    "    frequent_dict = []\n",
    "    for idx in range(len(c1)):\n",
    "        if supports[idx] >= min_support:\n",
    "            item_set.append(c1[idx])\n",
    "            frequent_dict.append((c1[idx], supports[idx]))\n",
    "\n",
    "    # generate new candidates\n",
    "    temp = list(itertools.combinations(item_set, 2))\n",
    "    temp = [set.union(combination[0], combination[1]) for combination in temp]\n",
    "    new_item_set = []\n",
    "    [new_item_set.append(candidate) for candidate in temp if not i in new_item_set]\n",
    "\n",
    "    return frequent_dict, new_item_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1735,
   "outputs": [],
   "source": [
    "# a helper function use to get the subsets with a specific length from a iterable object\n",
    "def power_set(iterable):\n",
    "    s = list(iterable)\n",
    "    return itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(len(s) + 1))\n",
    "\n",
    "def k_subsets(s, k):\n",
    "    return [set(item) for item in power_set(s) if len(item) == k]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1736,
   "outputs": [],
   "source": [
    "# general scan function\n",
    "def scan(data_set, ck, min_support, print_flag=False):\n",
    "    supports = [0 for candidate in ck]\n",
    "    fre_data_sets = []\n",
    "\n",
    "    # count support of these candidates\n",
    "    for transaction in data_set:\n",
    "        fre_flag = False\n",
    "        for candidate in ck:\n",
    "            if candidate.issubset(transaction):\n",
    "                supports[ck.index(candidate)] += 1\n",
    "                fre_flag = True\n",
    "\n",
    "        # save the frequent transactions for the next scan, and discard the infrequent ones\n",
    "        if fre_flag:\n",
    "            fre_data_sets.append(transaction)\n",
    "\n",
    "    # compare candidates with min_support\n",
    "    frequent_item_sets = []\n",
    "    frequent_dict= []\n",
    "    for idx in range(len(ck)):\n",
    "        if supports[idx] >= min_support:\n",
    "            frequent_item_sets.append(ck[idx])\n",
    "            frequent_dict.append((ck[idx], supports[idx]))\n",
    "            if print_flag:\n",
    "                print(ck[idx], supports[idx])\n",
    "\n",
    "    if not frequent_item_sets:\n",
    "        return []\n",
    "\n",
    "    # generate new candidates\n",
    "    k_num = len(frequent_item_sets[0])\n",
    "\n",
    "    temp = list(itertools.combinations(frequent_item_sets, 2))\n",
    "    temp = [combination[0].union(combination[1]) for combination in temp\n",
    "            if combination[0]&combination[1] and len(combination[0]&combination[1]) == k_num-1]\n",
    "\n",
    "    new_item_set = []\n",
    "\n",
    "    # check whether those candidates repeated or have infrequent subsets\n",
    "    for candidate in temp:\n",
    "        if candidate not in new_item_set:\n",
    "            subsets = k_subsets(candidate, k_num)\n",
    "            flag = True\n",
    "            for item in subsets:\n",
    "                if item not in frequent_item_sets:\n",
    "                    flag = False\n",
    "                    break\n",
    "            if flag:\n",
    "                new_item_set.append(candidate)\n",
    "\n",
    "    return frequent_dict, new_item_set, fre_data_sets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1737,
   "outputs": [],
   "source": [
    "# integrate previous functions\n",
    "\n",
    "def apriori(data_set, min_sup):\n",
    "    frequent_item_set = []\n",
    "\n",
    "    temp_frequent_dict, ck = first_scan(data_set, min_sup)\n",
    "    frequent_item_set += temp_frequent_dict\n",
    "\n",
    "    while ck:\n",
    "        temp_frequent_dict, ck, data_set = scan(data_set, ck, min_sup)\n",
    "        frequent_item_set += temp_frequent_dict\n",
    "\n",
    "    return frequent_item_set\n",
    "\n",
    "adult_fre_item_set1 = apriori(adult_data[:100], 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1738,
   "outputs": [],
   "source": [
    "# fp tree node\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, item, fre_count):\n",
    "        self.item = item\n",
    "        self.fre_count = fre_count\n",
    "        self.children = set()\n",
    "        self.node_link = None\n",
    "\n",
    "    def increment(self, fre=1):\n",
    "        self.fre_count += fre\n",
    "\n",
    "    def add_child(self, new_node):\n",
    "        self.children.add(new_node)\n",
    "        return new_node\n",
    "\n",
    "    def get_child(self, item):\n",
    "        for child in self.children:\n",
    "            if child.item == item:\n",
    "                return child\n",
    "        return None\n",
    "\n",
    "    def display(self, level=0):\n",
    "        print(\"|\"*level+\"-\" ,self.item, self.fre_count)\n",
    "        for child in self.children:\n",
    "            child.display(level+1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1739,
   "outputs": [],
   "source": [
    "#transfer the data set to vertical version with a head table\n",
    "def vertical_transfer(data_set, min_sup, frequency=None):\n",
    "    if frequency:\n",
    "        vertical_data = {}\n",
    "        # generate the head table only with a frequency input\n",
    "        for i in range(len(data_set)):\n",
    "            fre_count = frequency[i]\n",
    "            for item in data_set[i]:\n",
    "                if not item in vertical_data.keys():\n",
    "                    vertical_data[item] = fre_count\n",
    "                else:\n",
    "                    vertical_data[item] += fre_count\n",
    "\n",
    "        item_seq = [[key, value, None] for key, value in vertical_data.items() if value >= min_sup]\n",
    "        item_seq.sort(key=(lambda x: x[1]), reverse=True)\n",
    "\n",
    "        return item_seq\n",
    "\n",
    "    else:\n",
    "        vertical_data = {}\n",
    "        item_seq = []\n",
    "        # generate the vertical data set\n",
    "        for transaction in data_set:\n",
    "            for item in transaction:\n",
    "                if not item in vertical_data.keys():\n",
    "                    vertical_data[item] = [transaction]\n",
    "                    item_seq.append(item)\n",
    "                else:\n",
    "                    vertical_data[item].append(transaction)\n",
    "\n",
    "        item_seq = [[item, len(vertical_data[item]), None] for item in item_seq if len(vertical_data[item]) >= min_sup]\n",
    "        item_seq.sort(key=(lambda x: x[1]), reverse=True)\n",
    "\n",
    "        return vertical_data, item_seq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1740,
   "outputs": [],
   "source": [
    "# function construct the fp tree\n",
    "def tree_construction(data_set, min_sup, display=False):\n",
    "    vertical_data, head_table = vertical_transfer(data_set, min_sup)\n",
    "\n",
    "    fp_tree = Node(None, -1)\n",
    "\n",
    "    # scan the data_set again\n",
    "    for transaction in data_set:\n",
    "        current_node = fp_tree\n",
    "        for item in head_table:\n",
    "            if item[0] in transaction:\n",
    "                child_node = current_node.get_child(item[0])\n",
    "                if child_node:\n",
    "                    child_node.increment()\n",
    "                else:\n",
    "                    child_node = current_node.add_child(Node(item[0], 1))\n",
    "                    if item[2]:\n",
    "                        next_link = item[2]\n",
    "                        while next_link.node_link:\n",
    "                            next_link = next_link.node_link\n",
    "                        next_link.node_link = child_node\n",
    "                    else:\n",
    "                        item[2] = child_node\n",
    "\n",
    "                current_node = child_node\n",
    "\n",
    "    if display:\n",
    "        for line in head_table:\n",
    "            print(line)\n",
    "        fp_tree.display()\n",
    "\n",
    "    return head_table, fp_tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1741,
   "outputs": [],
   "source": [
    "# generate conditional pattern base from a fp tree\n",
    "def mine_fp_tree(fp_tree: Node, curr_path, conditional_pattern_base):\n",
    "    for child in fp_tree.children:\n",
    "        if child.item in conditional_pattern_base.keys():\n",
    "            conditional_pattern_base[child.item][0].append(curr_path.copy())\n",
    "            conditional_pattern_base[child.item][1].append(child.fre_count)\n",
    "        else:\n",
    "            conditional_pattern_base[child.item] = ([curr_path.copy()], [child.fre_count])\n",
    "        mine_fp_tree(child, curr_path+[child.item], conditional_pattern_base)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1742,
   "outputs": [],
   "source": [
    "# generate the frequent pattern from a sub frequent tree\n",
    "def mine_sub_fp_tree(fp_tree: Node, curr_path, p_sets):\n",
    "    if fp_tree.children:\n",
    "        for child in fp_tree.children:\n",
    "            mine_sub_fp_tree(child, curr_path.union({child.item}), p_sets)\n",
    "    else:\n",
    "        for p_set in p_sets:\n",
    "            if p_set[0].issubset(curr_path) and fp_tree.fre_count >= 0:\n",
    "                p_set[1] += fp_tree.fre_count\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1743,
   "outputs": [],
   "source": [
    "def min_cp_base(conditional_pattern_base:dict, min_sup:int):\n",
    "    frequent_pattern = []\n",
    "\n",
    "    # go through each item in the conditional pattern base\n",
    "    for item_name, cpb in conditional_pattern_base.items():\n",
    "        sub_fp_tree = Node(None, -1)\n",
    "        paths = cpb[0]\n",
    "        frequencies = cpb[1]\n",
    "        head_table = vertical_transfer(paths, min_sup, frequencies)\n",
    "\n",
    "        # similar to the main fp tree construction, construct the sub fp tree\n",
    "        for i in range(len(paths)):\n",
    "            current_node = sub_fp_tree\n",
    "            path = paths[i]\n",
    "            frequency = frequencies[i]\n",
    "\n",
    "            for item in head_table:\n",
    "                if item[0] in path:\n",
    "                    child_node = current_node.get_child(item[0])\n",
    "                    if child_node:\n",
    "                        child_node.increment(frequency)\n",
    "                    else:\n",
    "                        child_node = current_node.add_child(Node(item[0], frequency))\n",
    "                        if item[2]:\n",
    "                            next_link = item[2]\n",
    "                            while next_link.node_link:\n",
    "                                next_link = next_link.node_link\n",
    "                            next_link.node_link = child_node\n",
    "                        else:\n",
    "                            item[2] = child_node\n",
    "\n",
    "                    current_node = child_node\n",
    "\n",
    "        #generate the frequent of each subtree\n",
    "        possible_item_sets = [[set(item), 0] for item in power_set({item[0] for item in head_table}.union({item_name}))\n",
    "                              if len(item) > 2 and item_name in item]\n",
    "\n",
    "        mine_sub_fp_tree(sub_fp_tree, {item_name}, possible_item_sets)\n",
    "\n",
    "        frequent_pattern += ([({item_name, item[0]}, item[1]) for item in head_table] +\n",
    "                             [tuple(item_set) for item_set in possible_item_sets if item_set[1]>=min_sup])\n",
    "\n",
    "    return frequent_pattern"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1744,
   "outputs": [],
   "source": [
    "def fp_growth(data_base, min_sup):\n",
    "    head_table, fp_tree = tree_construction(data_base, min_sup)\n",
    "    frequent_item_set = [({item[0]}, item[1]) for item in head_table]\n",
    "    cp_base = {}\n",
    "    mine_fp_tree(fp_tree, [], cp_base)\n",
    "    frequent_item_set += min_cp_base(cp_base, min_sup)\n",
    "    return frequent_item_set\n",
    "\n",
    "adult_fre_item_set2 = fp_growth(adult_data[:100], 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1745,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori Male => {Male, United-States}, Confidence = 0.8513513513513513\n",
      "FP-Growth Male => {Male, United-States}, Confidence = 0.8513513513513513\n"
     ]
    }
   ],
   "source": [
    "# the confidence for two frequent item sets\n",
    "def confidence(frequent_item0, frequent_item1, frequent_item_set):\n",
    "    union = frequent_item0.union(frequent_item1)\n",
    "    union_support = 0\n",
    "    item0_support = 0\n",
    "\n",
    "    for item in frequent_item_set:\n",
    "        if item[0] == union:\n",
    "            union_support = item[1]\n",
    "        if item[0] == frequent_item0:\n",
    "            item0_support = item[1]\n",
    "        if union_support and item0_support:\n",
    "            break\n",
    "    if item0_support:\n",
    "        return union_support/item0_support\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print('Apriori Male => {Male, United-States}, Confidence =',\n",
    "      confidence({'Male'}, {'Male', 'United-States'} ,adult_fre_item_set1))\n",
    "\n",
    "print('FP-Growth Male => {Male, United-States}, Confidence =',\n",
    "      confidence({'Male'}, {'Male', 'United-States'} ,adult_fre_item_set2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-74842517",
   "language": "python",
   "display_name": "PyCharm (CSC240)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}